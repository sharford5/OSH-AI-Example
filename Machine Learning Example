{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Learning Example","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Machine Learning Demostration using Fitbit Data\n","\n","[Data Source](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ZS2Z2J) \n"],"metadata":{"id":"QTpBEAMojnI0"}},{"cell_type":"markdown","source":["About Colab and Python:<br>\n","\n","First lets give this notebook access to your Google Drive. To do this <font color='red'>click</font> the <font color='orange'>'Files'</font> Button on the left tool bar. Then <font color='red'>click</font> the <font color='orange'>'Mount Drive'</font> button and follow steps.<br>\n","\n","Colab is a Google Cloud Environment that allows the user to run Python code using a web browser. This notebook is precoded to explore the Machine Learning Example.<br>\n","\n","To use this notebook <font color='red'>click</font> the <font color='orange'>'Run Cell'</font> Button (looks like a play icon) on the left side of each cell. This button will execute the code in the cell and print out the output below the cell<br>\n","\n","As you go throught the notebook, there will be <font color='green'>'Forms'</font> on the right side of some cells. These forms allow you to interact with the code without knowledge of programming.\n"],"metadata":{"id":"xFHgowUc3xZh"}},{"cell_type":"markdown","source":["#Section 0: Notebook Setup\n"],"metadata":{"id":"FuKi-8hQk15Z"}},{"cell_type":"markdown","source":["This call changes the directory of the notebook so that the code can access the data."],"metadata":{"id":"50vrbZkq8UWH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0jVQge8o8U3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652549509774,"user_tz":240,"elapsed":20435,"user":{"displayName":"Samuel Harford","userId":"06799438285463246538"}},"outputId":"a7405a9e-eb59-46bc-f31a-f3f7a30b2f95"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZnB6cTfmkzyp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652549519716,"user_tz":240,"elapsed":1017,"user":{"displayName":"Samuel Harford","userId":"06799438285463246538"}},"outputId":"da1957d7-c7bf-4e36-8ef6-8ce1059c31ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'drive/MyDrive/you': No such file or directory\n","Output: The Following is the current directory\n","/content/drive/Shareddrives/OSH & AI /MachineLearningPresentationCode\n"," data  'Machine Learning Example'   utils\n"]}],"source":["#Import in the Operating Systems package\n","import os\n","#Change the directory to the project of interest\n","os.chdir('drive/My Drive/MachineLearningPresentationCode/')\n","# os.chdir('drive/Shareddrives/OSH & AI /MachineLearningPresentationCode/')\n","\n","#Print the files/folders in the current directory to verify the current files (! means the command is a linux operation)\n","print(\"Output: The Following is the current directory\")\n","!pwd\n","!ls"]},{"cell_type":"markdown","source":["This cell loads in the requires packages for the code in the notebook"],"metadata":{"id":"ycGU3C9YWxXW"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from utils.data_processing import load_data, process_data, split_data\n","from utils.model_utils import parameters_fit\n","from utils.ci_auc import calculate_auc_ci\n","import plotly.express as px\n","\n","from sklearn.metrics import plot_confusion_matrix, accuracy_score, roc_auc_score\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.experimental import enable_halving_search_cv \n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","import xgboost as xgb\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from utils.model_utils import parameters_fit, param_grid\n","from sklearn.model_selection import HalvingGridSearchCV\n","print(\"Output: All packages successfully loaded\")"],"metadata":{"id":"MFNbJnOLktcY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 1: Data Preprocessing and Exploration"],"metadata":{"id":"eqvJ-SZepvFX"}},{"cell_type":"markdown","source":["This cell loads in the data for the notebook and explains the information in the data."],"metadata":{"id":"hZLdoCaD-gtF"}},{"cell_type":"code","source":["#Load in the dataset\n","data = load_data()\n","#Output the first 5 rows of the dataframe\n","print(\"Output: The following shows the first 5 rows of the loaded data\")\n","print(\"The column 'Instance' indicates that the first rows below the the same person, there are 98 instaces in the data\")\n","print(\"The last column 'activity' is the column of interest for modeling\")\n","print(\"All other columns are information that can be used for modeling\")\n","data.head()"],"metadata":{"id":"uxy0kPkqp0GV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This cell takes a look at the labels ('activity') for the data."],"metadata":{"id":"WQLL-uBMACTr"}},{"cell_type":"code","source":["#Put the activities into a list\n","labels = list(data['activity'])\n","#Get the unique activities\n","l_list = list(np.unique(labels))\n","#Create a dictionary of the activities and the assigned category/number\n","l_dic = {i:l_list[i] for i in range(len(l_list))}\n","\n","print(\"Output: The following shows the possibilities of the labels/activity\")\n","#Output the dictionary\n","l_dic"],"metadata":{"id":"aeAQ6LSosI95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next cell explores the data using box-plot visualizations. This box-plot explores a single input feature (y-axis or vertical axis) compared to the label (x-axis or horizontal axis.<br>\n","<font color='green'>Use the Form on the right to select the feature of interest. </font> <br>\n","The illustrated example of 'norm_heart' shows that as the activity becomes more intense the norm heart value is increasing (based on the median)."],"metadata":{"id":"Pf5av6RKBe4r"}},{"cell_type":"code","source":["#@title Form: Select Feature to Plot\n","#Feature of Interest\n","Feature = 'norm_heart' #@param [\"age\",\"gender\",\"height\",\"weight\",\"steps\",\"hear_rate\",\"calories\",\"distance\",\"entropy_heart\",\"entropy_setps\",\"resting_heart\",\"corr_heart_steps\",\"norm_heart\",\"intensity_karvonen\",\"sd_norm_heart\",\"steps_times_distance\"]\n","#Plot a box chart for that feature\n","fig = px.box(data, x='activity', y=Feature)\n","print(\"Output:\")\n","fig.show()"],"metadata":{"id":"SdyQ0Ceeb4sb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next cell explores the data using scatter plot visualizations. This plot explores two input features and uses color to visualize the label/activity.<br>\n","<font color='green'>Use the Form on the right to select the features of interest. </font> <br>\n","The illustrated example of 'resting_heart' vs. 'heart_rate' may appear unclear but there is a little information that can be drawn. Such as the 'resting_heart' being above 100 typically corresponds with movement. "],"metadata":{"id":"GkD9-GZWLYOY"}},{"cell_type":"code","source":["#@title Form: Select two different features to Plot\n","Feature1 = 'resting_heart' #@param [\"age\",\"gender\",\"height\",\"weight\",\"steps\",\"heart_rate\",\"calories\",\"distance\",\"entropy_heart\",\"entropy_setps\",\"resting_heart\",\"corr_heart_steps\",\"norm_heart\",\"intensity_karvonen\",\"sd_norm_heart\",\"steps_times_distance\"]\n","Feature2 = 'heart_rate' #@param [\"age\",\"gender\",\"height\",\"weight\",\"steps\",\"heart_rate\",\"calories\",\"distance\",\"entropy_heart\",\"entropy_setps\",\"resting_heart\",\"corr_heart_steps\",\"norm_heart\",\"intensity_karvonen\",\"sd_norm_heart\",\"steps_times_distance\"]\n","\n","fig = px.scatter(data, x=Feature1, y=Feature2, color='activity')\n","print(\"Output:\")\n","fig.show()"],"metadata":{"id":"-0wbr5nQoonm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This next cell normalizes the data for use in modeling. In this code block, the data for each column is normalized better 0 and 1. The normalization process is a typical preprocessing set when the data ranges are very different such as that of height and calories.<br>\n","<font color='green'>Use the Form on the right to decide if you want to normalize the data. </font> <br>\n","\n","\n"],"metadata":{"id":"at4JrlQrMfOw"}},{"cell_type":"code","source":["#@title Form: Should this data be normalized\n","Normalize = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","if Normalize:\n","    print(\"Output: Data Normalized. The following is the Normalized Data.\")\n","    data = process_data(data)\n","    #Output the first 5 rows of the dataframe\n","else:\n","    print(\"Output: Data NOT Normalized. The following is the Unormalized Data.\")\n","\n","data.head()"],"metadata":{"id":"eY3FPudyp0hD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This cell handles the categorical values of the current dataframe. This includes 'device' which is a possible input feature to the model, and 'activity' which is the output label of interest for the model. Categorical values of this type must for converted to encoded representations in order for the models to process the information. "],"metadata":{"id":"S6zr_l95NbPS"}},{"cell_type":"code","source":["#Convert Categorical Values to Coded Values\n","data['device'] = data['device'].astype('category')\n","data['device'] = data['device'].cat.codes\n","data['activity'] = data['activity'].astype('category')\n","data['activity'] = data['activity'].cat.codes\n","print(\"Output: This is the new data with 'device' and 'activity' converted to numbers\")\n","data.head()"],"metadata":{"id":"16SE5HmuvIZ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code generates the machine learning modeling datasets. For this we need to split the data into Train, Validataion and Test datasets. Each datasets has a X and y component where X is the input information for model learning and y is the target label or activity. <br><br>\n","There is 98 instances in the overall datasets. For this example 53 are used for Train, 15 for Validataion, and 30 for Test. Each instance has several readings with associated labels."],"metadata":{"id":"e9XQALE0O8Sd"}},{"cell_type":"code","source":["#Subset the dataset into Training, Validation, and Testing\n","#There are 98 'Instance's in the dataset\n","#p_test is the number assigned to the testing sets, p_val is the number assigned to the Validataion set \n","X_train_full, X_val_full, X_test_full, y_train, y_val, y_test, cols = split_data(data, p_test=25, p_val=10)\n","\n","print(\"Output: The following is the shape of the 3 datasets where the first number is the number of readings \")\n","print(\"and the second is the number of features\")\n","print(\"Train Shape: \", X_train_full.shape)\n","print(\"Validataion Shape: \", X_val_full.shape)\n","print(\"Test Shape: \", X_test_full.shape)"],"metadata":{"id":"ZyVU4poKvLhe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next cell goes over the features utilized in the model developement process. <br>\n","<font color='green'>Use the Form on the right to decide which features to use (where True means use). </font> <br>\n","Feature selection is an important part of machine learning to maximize the amount of information the model has to learn from without giving it too much noise. \n"],"metadata":{"id":"YCJ9YeUKVHM8"}},{"cell_type":"code","source":["#@title Use the following dropdown options to determine if a feature is used for modeling (True means include)\n","age = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","gender = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","height = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","weight = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","steps = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","heart_rate = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","calories = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","distance = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","entropy_heart = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","calories = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","entropy_setps = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","resting_heart = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","corr_heart_steps = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","norm_heart = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","intensity_karvonen = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","sd_norm_heart = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","steps_times_distance = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","device = True #@param [\"False\", \"True\"] {type:\"raw\"}\n","\n","features = [\n","            'age',\n","            'gender',\n","            'height',\n","            'weight',\n","            'steps',\n","            'heart_rate',\n","            'calories',\n","            'distance',\n","            'entropy_heart',\n","            'entropy_setps',\n","            'resting_heart',\n","            'corr_heart_steps',\n","            'norm_heart',\n","            'intensity_karvonen',\n","            'sd_norm_heart',\n","            'steps_times_distance',\n","            'device'\n","]\n","\n","features_used = []\n","count = 0\n","for option in [age, gender, height, weight, steps, heart_rate, calories, distance, entropy_heart, entropy_setps, resting_heart, corr_heart_steps, norm_heart, intensity_karvonen, sd_norm_heart, steps_times_distance, device]:\n","    if option:\n","        features_used.append(features[count])\n","    count+=1\n","\n","#Create a list of the columns numbers used for modeling\n","cols_used = [cols.index(f)+1 for f in features_used]\n","\n","#Subset the modeling sets based on the columns used\n","X_train = X_train_full[:, cols_used]\n","X_val = X_val_full[:, cols_used]\n","X_test = X_test_full[:, cols_used]\n","  \n","print(\"Output: These are the Features available and if they are selected\")\n","for f in features:\n","    value = \"Selected\" if f in features_used else \"Not Selected\"\n","    print('%s: %s' % (f, value))\n"],"metadata":{"id":"T4hd0SYkt_AT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Section 2: Machine Learning Modeling\n","\n","The following are links to the documentation for each of the available machine learning algorithms.<br>\n","[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) "],"metadata":{"id":"U2gUUnucznkL"}},{"cell_type":"markdown","source":["This next code block trains the model using the preprocessed data. Use Commenting to select the model for training and parameters of that model. The above links show the details of the algorithms."],"metadata":{"id":"OTWSqq7ByXlh"}},{"cell_type":"code","source":["#@title Form: Select the Machine Learning Model to Use\n","Model_Selected = 'XGBoost' #@param [\"Support Vector Machine\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"]\n","#@markdown Do you want the parameters to be optimized for you?\n","Search_Parameters = False #@param [\"False\", \"True\"] {type:\"raw\"}\n","#@markdown If not, lets manually select the parameters associated with the selected model. The following are all the parameter options. Please only modify the parameters that impact your selected model. These parameter associations are as follows:<br><br>\n","#@markdown **Support Vector Machine**: C, Kernel <br>\n","#@markdown **Decision Tree**: MaxDepth <br>\n","#@markdown **Random Forest**: NumberEstimators, MaxDepth, MinSampleSplits <br>\n","#@markdown **XGBoost**: NumberEstimators, MaxDepth, MinChildWeight, Gamma <br>\n","\n","NumberEstimators = 1250 #@param {type:\"integer\"}\n","MaxDepth =  7#@param {type:\"integer\"}\n","C = 2.2 #@param {type:\"slider\", min:0.5, max:5, step:0.1}\n","MinChildWeight =  5#@param {type:\"integer\"}\n","MinSampleSplits = 2 #@param {type:\"integer\"}\n","Gamma = 0.9 #@param {type:\"slider\", min:0.5, max:5, step:0.1}\n","Kernel = 'rbf' #@param ['linear', 'poly', 'rbf']\n","\n","\n","#Define the model for classification\n","if Model_Selected == 'Random Forest':\n","    model = RandomForestClassifier(random_state=0, n_estimators=NumberEstimators, max_depth=MaxDepth) \n","elif Model_Selected == 'Support Vector Machine':\n","    model = SVC(C=C)\n","elif Model_Selected == 'Decision Tree':\n","    model = DecisionTreeClassifier(max_depth=MaxDepth)\n","elif Model_Selected == 'XGBoost':\n","    model = xgb.XGBClassifier(random_state=0, n_estimators=NumberEstimators, max_depth=MaxDepth)\n","\n","#Optimize Parameters\n","if Search_Parameters:\n","    print(\"Searching Parameters...\")\n","    gs = HalvingGridSearchCV(model, param_grid[Model_Selected], cv=3, factor=2).fit(X_train, y_train)\n","    print(\"Optimal Parameter Set: \", gs.best_params_)\n","    print(\"New Model: \", gs.best_estimator_)\n","    model = gs.best_estimator_\n","\n","#Train the modeling utilizing the Training Data\n","print(\"Training New Model...\")\n","model.fit(X_train, y_train)\n","\n","#Predict the Training set using the Training Model\n","pred_train = model.predict(X_train)\n","\n","#Convert labels back to the original\n","pred_train_map = np.asarray([l_dic[letter] for letter in pred_train])\n","y_train_map = np.asarray([l_dic[letter] for letter in y_train])\n","\n","print(\"Model Selected: %s\" % Model_Selected)\n","#Print the label dictionary for reference\n","print(\"Labels:\")\n","print(l_dic)\n","\n","#Compute and output the accuracy\n","acc = accuracy_score(y_train, pred_train)\n","print(\"Accuracy: %s\" % acc)\n","\n","#Display the confusion matrix of the validataion Model\n","plot_confusion_matrix(model, X_train, y_train)\n"],"metadata":{"id":"Ee825IIuznMi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next code evaluates the Validataion Data. This evaluation is unseen during the traing process and can be used for parameter tuning."],"metadata":{"id":"LluXEo-wyyfY"}},{"cell_type":"code","source":["#Predict the Validataion set using the Training Model\n","pred_val = model.predict(X_val)\n","\n","#Convert labels back to the original\n","pred_val_map = np.asarray([l_dic[letter] for letter in pred_val])\n","y_val_map = np.asarray([l_dic[letter] for letter in y_val])\n","\n","#Print the label dictionary for reference\n","print(l_dic)\n","\n","#Compute and output the accuracy\n","acc = accuracy_score(y_val, pred_val)\n","print(\"Accuracy: %s\" % acc)\n","\n","# #Compute and output the AUC. (TODO)\n","# au = roc_auc_score(y_val, pred_val, multi_class='ovr')\n","# print(\"AUC: %s\" % au)\n","\n","#Display the confusion matrix of the validataion Model\n","plot_confusion_matrix(model, X_val, y_val)\n"],"metadata":{"id":"JcZ4rs94101_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code block evaluates the model using the Testing Data. This is an evaluation that sees how well you can expect the model to generalize to unseen/new data."],"metadata":{"id":"QHyUos8SzIS7"}},{"cell_type":"code","source":["#Predict the Testing set using the Training Model\n","pred_test = model.predict(X_test)\n","\n","#Convert labels back to the original\n","pred_test_map = np.asarray([l_dic[letter] for letter in pred_test])\n","y_test_map = np.asarray([l_dic[letter] for letter in y_test])\n","\n","#Print the label dictionary for reference\n","print(l_dic)\n","\n","#Compute and output the accuracy\n","acc = accuracy_score(y_test, pred_test)\n","print(\"Accuracy: %s\" % acc)\n","\n","# #Compute and output the AUC. (TODO)\n","# au = roc_auc_score(y_val, pred_val, multi_class='ovr')\n","# print(\"AUC: %s\" % au)\n","\n","#Display the confusion matrix of the validataion Model\n","plot_confusion_matrix(model, X_test, y_test)\n"],"metadata":{"id":"JAT64OXA0DUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_curve, auc\n","\n","pred_test2 = np.zeros((pred_test.size, pred_test.max()+1))\n","pred_test2[np.arange(pred_test.size),pred_test] = 1\n","print(pred_test2.shape)\n","\n","y_test2 = np.zeros((y_test.size, y_test.max()+1))\n","y_test2[np.arange(y_test.size),y_test] = 1\n","print(y_test2.shape)\n","\n","n_classes=6\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test2[:, i], pred_test2[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot of a ROC curve for a specific class\n","for i in range(n_classes):\n","    plt.figure()\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic example (Class %s)' %i)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n"],"metadata":{"id":"GbrEQWsbzzgK"},"execution_count":null,"outputs":[]}]}